1. Introducing word representation 
> 1. Noah A. Smith, [Contextual Word Representations: Putting Words into Computers](https://cacm.acm.org/magazines/2020/6/245162-contextual-word-representations/fulltext), Communications of the ACM, June 2020, Vol. 63 No. 6, Pages 66-74
10.1145/3347145 


2. Language models
> 1. Hang Li, [Language Models: Past, Present, and Future](https://cacm.acm.org/magazines/2022/7/262080-language-models/fulltext), Communications of the ACM, July 2022, Vol. 65 No. 7, Pages 56-63
10.1145/3490443
> 2. [A Primer in BERTology: What We Know About How BERT Works](https://aclanthology.org/2020.tacl-1.54) (Rogers et al., TACL 2020)

> 3. Large Language Model (LLM) size, performance and resource needs 
> > a. Trade-offs - [In AI, is bigger always better?](https://www.nature.com/articles/d41586-023-00641-w), March 2023.

> > b. "22 times lesser energy thar regular LLM"  - [SpikeGPT: researcher releases code for largest-ever spiking neural network for language generation](https://news.ucsc.edu/2023/03/eshraghian-spikegpt.html), March 2023

> 4. [ChatGPT](https://openai.com/blog/chatgpt/), from OpenAI - LLM for dialogs
> > a. About the technology
> > > 1. [The Brilliance and Weirdness of ChatGPT](https://www.nytimes.com/2022/12/05/technology/chatgpt-ai-twitter.html) [NY Times, Dec 2022]
> > > 2. [ChatGPT is 'not particularly innovative,' and 'nothing revolutionary', says Meta's chief AI scientist](https://www.zdnet.com/article/chatgpt-is-not-particularly-innovative-and-nothing-revolutionary-says-metas-chief-ai-scientist/) [Yann LeCun, Jan 2023]
> > > 3. [ChatGPT is not all you need. A State of the Art Review of large Generative AI models](https://arxiv.org/abs/2301.04655) [Jan 2023]
> > > 4. [Working with ChatGPT-like LLM-based-AIs Reliably: Don’t Look at Only the Technology Pillar For All The Answers](https://www.linkedin.com/pulse/working-chatgpt-like-llm-based-ais-reliably-dont-look-srivastava/) [Biplav Srivastava, Jan 2023]. _Argues that beyond technology, user education, regulation and standards are need to mature any technology, and now AI_
> > > 5. [Will ChatGPT supplant us as writers, thinkers?](https://news.harvard.edu/gazette/story/2023/02/will-chatgpt-replace-human-writers-pinker-weighs-in/) [Steven Pinker, Feb 2023]
> > > 6. [Beauty, lies & ChatGPT: Welcome to the post-truth world](https://thehill.com/opinion/technology/3861182-beauty-lies-chatgpt-welcome-to-the-post-truth-world/) [Subbaro Kambhampati, Feb 2023]. _Says that ChatGPT can help in framing search questions but cannot link to data source to prove results truthfulness._

> > b. Passing tests
> > > 1. [ChatGPT passes MBA exam given by a Wharton professor](https://www.nbcnews.com/tech/tech-news/chatgpt-passes-mba-exam-wharton-professor-rcna67036) [Passing test with B grade at Wharton, Jan 2023]
> > > 2. [ChatGPT passes exams from law and business schools](https://www.cnn.com/2023/01/26/tech/chatgpt-passes-exams/index.html) [Jan 2023]
> > > 3.  [How Smart Are the Robots Getting?](https://www.nytimes.com/2023/01/20/technology/chatbots-turing-test.html) [Chatbots and Turing test, NY Time, Jan 2023]
> > > 4. [Real estate agents say they can’t imagine working without ChatGPT now](https://www.cnn.com/2023/01/28/tech/chatgpt-real-estate/index.html)  [Real-estate industry and ChatGPT, Jan 2023]

> > c. Errors by language models
> > 1. [Large Language Models like ChatGPT say The Darnedest Things](https://garymarcus.substack.com/p/large-language-models-like-chatgpt) [A collection of mistakes by LLMs]
> > 2. [ChatGPT mistakes](https://github.com/giuven95/chatgpt-failure) [A GitHub of mistakes]

3. Text classification, learning
> 1. Shervin Minaee, Nal Kalchbrenner, Erik Cambria, Narjes Nikzad, Meysam Chenaghlu, and Jianfeng Gao. 2021. [Deep Learning--based Text Classification: A Comprehensive Review](https://dl.acm.org/doi/abs/10.1145/3439726). ACM Comput. Surv. 54, 3, Article 62 (April 2022), 40 pages. https://doi.org/10.1145/3439726

4. AI, language and human understanding
> 1. [AI And The Limits Of Language](https://www.noemamag.com/ai-and-the-limits-of-language/),  Jacob Browning and Yann LeCun, Aug 2022. _Argues that not all human knowledge is in text, and so, any AI trained on it will struggle_.
> 2. Weidinger, Laura, et al., [Taxonomy of Risks posed by Language Models](https://dl.acm.org/doi/10.1145/3531146.3533088), 2022 ACM Conference on Fairness, Accountability, and Transparency.

5. NLP Datasets and Tasks 
> 1. Data - [Introduction to the CoNLL-2002 Shared Task: Language-Independent Named Entity Recognition](https://aclanthology.org/W02-2024/). Extraction in Dutch and Spanish.
> 2. Data - [Introduction to the CoNLL-2003 Shared Task: Language-Independent Named Entity Recognition](https://paperswithcode.com/dataset/conll-2003). Extraction in English and German.

6. NLP Packages
> 1. See [Useful NLP Packages](https://github.com/biplav-s/course-nl/blob/8f0bb9e50db6706595e6d5ca38c39d31e9bfc77b/resources/UsefulNLPPackages.md) resources from CSCE 771 - Fall 2020

7. NLP Applications
> 1. Yufeng Huang, Mariana Bernagozzi, Michelle Morales, Sheema Usmani, Biplav Srivastava, Michelle Mullins, [Clarity 2.0: Improved Assessment of Product Competitiveness from Online Content](https://ojs.aaai.org/index.php/aimagazine/article/view/15100). AI Mag. 42(2): 59-70 (2021)
> 2. [Artificial intelligence is helping scientists decode animal languages](https://www.popsci.com/technology/artificial-intelligence-animal-language/), Charlotte Hu, Popular Science, Sep 2022, 
